---
title: "Homework 2"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```


## R Markdown

## Question 2

#2(a), 2(b)

We start by applying Baye's formula. Then, we apply proportionality to recognize that the posterior is proportional to a known distribution. 

$$p(\theta|x_1,\ldots, x_n) = \frac{p(x_1,\ldots, x_n|\theta)p(\theta)}{p(x)}$$
Then: 
$$p(\theta|x_1,\ldots, x_n) \propto p(x_1,\ldots, x_n|\theta)p(\theta)$$
$$p(\theta|x_1,\ldots,x_n) \propto \frac{b^a}{\Gamma(a)}\theta^{a-1}e^{-b\theta}\theta^n*e^{-\theta*\sum_{i}x_i}$$
$$p(\theta|x_1,\ldots,x_n) \propto \theta^{a + n - 1}e^{-\theta(\sum_ix_i + b)}$$
$$p(\theta|x_1,\ldots,x_n) \propto \textrm{Gamma}(\theta| a + n, \sum_ix_i + b)$$
Thus the posterior distribution is proportional to a gamma distribution, and thus it is a proper distribution (integrates) to 1. We can calculate the normalizing constant by finding the value for $p(x)$.

$$p(x) = \int_{0}^1 \frac{b^a}{\Gamma(a)}\textrm{Gamma}(\theta|a+n,\sum_ix_i+b)d\theta$$
$$p(x) = \frac{b^a}{\Gamma(a)}\frac{\Gamma(a+n)}{(\sum_ix_i+b)^{a+n}}\int_{0}^1\frac{(\sum_ix_i+b)^{a+n}}{\Gamma(a+n)}\textrm{Gamma}(\theta|a+n,\sum_ix_i+b)d\theta$$
Since the integral is now a proper distribution, it integrates to 1. Thus we have: 
$$p(x) = \frac{b^a}{\Gamma(a)}\frac{\Gamma(a+n)}{(\sum_ix_i+b)^{a+n}}$$

and our full distribution:

$$p(x|\theta) = \frac{\Gamma(a)(\sum_ix_i+b)^{a+n}}{\Gamma(a+n)b^a}\textrm{Gamma}(\theta| a + n, \sum_ix_i + b)$$

#2(c)

```{r initialize}
obs.data = c(20.9, 69.7, 3.6, 21.8, 21.4, 0.4, 6.7, 10.0)
theta = seq(0,1,length = 1000)
prior = dgamma(theta, shape= .1, rate = 1)
sum = sum(obs.data)
posterior = dgamma(theta, shape = 8.1, rate = (sum + 1))
max(posterior)
```

```{r plotting}
plot(theta, prior,type = "l", ylab = "Density",
     lty = 3, lwd = 3, xlab = expression(theta))
par(new = TRUE)
plot(theta, posterior, type = "l",
     lty = 3, lwd = 3, axes = FALSE, col = "blue", 
     xlab = "", ylab = "") 
```

#2(d)

#3(a) 
```{r plotting}
y <- seq(0,1,by = .01)
galenshore <- function(y,a,theta){
 
  galenshore <- (2/gamma(a))*theta^(2*a)*y^(2*a-1)*exp((-theta^2)*y^2)
  return(galenshore)
}
plot(x = y, 
     y = galenshore(y,3,4), 
     ylab = "Density", 
     xlab = "y", 
     lty = 3, 
     lwd = 3)
par(new = TRUE)
plot(x = y, 
     y = galenshore(y,.2,.3), 
     axes = FALSE,
     lty = 3, 
     lwd = 3,
     col = "green",
     xlab = "",
     ylab = "")
par(new = TRUE)
plot(x = y, 
     y = galenshore(y,9,.001), 
     axes = FALSE,
     lty = 3, 
     lwd = 3,
     col = "blue",
     xlab = "",
     ylab = "")

```
I suspected that a Galenshore distribution will be a conjugate prior for itself, so I decided to pick this as my prior distribution. It turns out this is a good choice, as seen by the next part of the question. Above the plot of a few Galenshore distributions with 0 < y < 1. 

#3b
We will prove that the Galenshore distribution is a conjugate prior for itself, and prove the form of the posterior distribution. First we start with Baye's rule, with $\theta \sim \textrm{Galenshore}(c,d)$ and $Y_1,\ldots,Y_n | \theta \sim \textrm{Galenshore}(a,\theta)$.

$$p(\theta | y_1,\ldots,y_n) \propto p(y_1,\ldots,y_n | \theta)p(\theta)$$
$$p(\theta | y_1,\ldots,y_n) \propto  \left(\frac{2}{\Gamma(a)}\right)^n \theta^{2an}y^{(2a-1)n}e^{-\theta^2(\sum_i y_i^2)}\frac{2}{\Gamma(c)}d^{2c}\theta^{2c-1}e^{-d^2\theta^2}$$

This looks very complicated at first, but most of these things are constants if we treat this as a function of $\theta$. After removing constants, we have: 

$$p(\theta|y_1,\ldots,y_n) \propto \theta^{2an}e^{-\theta^2(\sum_i y_i^2)}\theta^{2c-1}e^{-d^2\theta^2}$$
If we combine like terms, we get: 

$$p(\theta | y_1,\ldots,y_n) \propto \theta^{2(an + c) -1}e^{-\theta^2\left(\left(\sum_i y_i^2\right) + d^2\right)}$$
We recognize this as the form of a Galenshore density, and we find that: 

$$p(\theta | y_1,\ldots,y_n) \propto \textrm{Galenshore}\left(an + c, \left(\sum_i y_i^2\right) + d^2 \right)$$
#2c
We need not know the constants for the Galenshore distribution when computing $\frac{p(\theta_a |y_1,\ldots,y_n)}{p(\theta_b |y_1,\ldots,y_n)}$ since they will be divided out anyways, so we can ignore writing them entirely. We write $s = \sum_i y_i^2$ to simplify notation. Now we simplify: 

$$\frac{p(\theta_a |y_1,\ldots,y_n)}{p(\theta_b |y_1,\ldots,y_n)} = \frac{\theta_a^{2(an + c) -1}e^{-\theta_a^2(s + d^2)}}{\theta_b^{2(an+c) -1}e^{-\theta_b^2(s + d^2)}}$$
Combining terms, we get: 

$$\frac{p(\theta_a |y_1,\ldots,y_n)}{p(\theta_b |y_1,\ldots,y_n)} = 
\left(\frac{\theta_a}{\theta_b}\right)^{2(an + c) - 1}\left(e^{(\theta_b^2 -\theta_a^2)(s + d^2)}\right)$$

This shows that, for fixed parameters $a,c,d$ we need only know $s$ to compute the probability density at $\theta_a$ relative to $\theta_b$. This means that $s$ is a sufficient statistic for our model. 

#2d

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
